{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CryoET Particle Detection Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements a 3D CNN for detecting and classifying particles in CryoET data.\n",
    "\n",
    "### Particle Types and Weights:\n",
    "- Apo-ferritin (weight: 1)\n",
    "- Beta-amylase (weight: 0)\n",
    "- Beta-galactosidase (weight: 2)\n",
    "- Ribosome (weight: 1)\n",
    "- Thyroglobulin (weight: 2)\n",
    "- Virus-like particle (weight: 1)\n",
    "\n",
    "### Evaluation Metric\n",
    "F-beta score with β=4 (heavily prioritizing recall over precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Constants\n",
    "PARTICLE_INFO = {\n",
    "    'apo-ferritin': {'radius': 60, 'weight': 1},\n",
    "    'beta-amylase': {'radius': 65, 'weight': 0},\n",
    "    'beta-galactosidase': {'radius': 90, 'weight': 2},\n",
    "    'ribosome': {'radius': 150, 'weight': 1},\n",
    "    'thyroglobulin': {'radius': 130, 'weight': 2},\n",
    "    'virus-like-particle': {'radius': 135, 'weight': 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class CryoETDataset(Dataset):\n",
    "    \"\"\"Dataset class for CryoET data\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir: str, mode: str = 'train', patch_size: int = 64):\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        # Get experiment directories\n",
    "        self.experiments = self._get_experiments()\n",
    "        \n",
    "        # Load annotations if in training mode\n",
    "        if mode == 'train':\n",
    "            self.annotations = self._load_annotations()\n",
    "            \n",
    "    def _get_experiments(self) -> List[str]:\n",
    "        \"\"\"Get list of experiment directories\"\"\"\n",
    "        exp_path = os.path.join(self.root_dir, 'static/ExperimentRuns')\n",
    "        return [d for d in os.listdir(exp_path) if os.path.isdir(os.path.join(exp_path, d))]\n",
    "    \n",
    "    def _load_annotations(self) -> Dict:\n",
    "        \"\"\"Load particle annotations from JSON files\"\"\"\n",
    "        annotations = {}\n",
    "        for exp in self.experiments:\n",
    "            picks_dir = os.path.join(self.root_dir, 'static/ExperimentRuns', exp, 'Picks')\n",
    "            if not os.path.exists(picks_dir):\n",
    "                continue\n",
    "                \n",
    "            exp_annotations = {}\n",
    "            for particle in PARTICLE_INFO.keys():\n",
    "                json_path = os.path.join(picks_dir, f'{particle}.json')\n",
    "                if os.path.exists(json_path):\n",
    "                    with open(json_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                        points = [[p['location']['x'], p['location']['y'], p['location']['z']]\n",
    "                                 for p in data.get('points', [])]\n",
    "                        exp_annotations[particle] = np.array(points)\n",
    "            \n",
    "            annotations[exp] = exp_annotations\n",
    "        return annotations\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.experiments)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        exp = self.experiments[idx]\n",
    "        data_path = os.path.join(self.root_dir, 'static/ExperimentRuns', \n",
    "                                exp, 'VoxelSpacing10.000/denoised.zarr')\n",
    "        \n",
    "        # Load tomogram\n",
    "        tomogram = zarr.open(data_path, mode='r')['0'][:]\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return self._get_training_item(tomogram, exp)\n",
    "        else:\n",
    "            return {\n",
    "                'tomogram': torch.FloatTensor(tomogram),\n",
    "                'experiment': exp\n",
    "            }\n",
    "    \n",
    "    def _get_training_item(self, tomogram: np.ndarray, exp: str) -> Dict:\n",
    "        \"\"\"Process training data with patches around particles\"\"\"\n",
    "        patches, labels = [], []\n",
    "        \n",
    "        for particle, coords in self.annotations[exp].items():\n",
    "            if PARTICLE_INFO[particle]['weight'] > 0:  # Skip beta-amylase\n",
    "                p, l = self._extract_patches(tomogram, coords)\n",
    "                patches.extend(p)\n",
    "                labels.extend(l)\n",
    "        \n",
    "        return {\n",
    "            'patches': torch.FloatTensor(patches),\n",
    "            'labels': torch.FloatTensor(labels),\n",
    "            'experiment': exp\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "3D U-Net style architecture with:\n",
    "- Encoder path with increasing channels (32→64→128→256)\n",
    "- Bridge connection (512 channels)\n",
    "- Decoder path with skip connections\n",
    "- Final 1x1 convolution for class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "class CryoETNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Encoder path\n",
    "        self.enc1 = self._make_encoder_block(32, 64)\n",
    "        self.enc2 = self._make_encoder_block(64, 128)\n",
    "        self.enc3 = self._make_encoder_block(128, 256)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = nn.Sequential(\n",
    "            nn.Conv3d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Decoder path\n",
    "        self.dec3 = self._make_decoder_block(512, 256)\n",
    "        self.dec2 = self._make_decoder_block(256, 128)\n",
    "        self.dec1 = self._make_decoder_block(128, 64)\n",
    "        \n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv3d(64, num_classes, kernel_size=1)\n",
    "        \n",
    "    def _make_encoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def _make_decoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.init_conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        \n",
    "        # Bridge\n",
    "        x5 = self.bridge(x4)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        x = self.dec3(x5) + x4\n",
    "        x = self.dec2(x) + x3\n",
    "        x = self.dec1(x) + x2\n",
    "        \n",
    "        return self.final_conv(x)"
   ]
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-beta Loss Implementation\n",
    "\n",
    "Custom loss function optimized for F-beta score (β=4) with:\n",
    "- Weighted particle importance\n",
    "- Precision-recall trade-off favoring recall\n",
    "- Micro-averaging across tomograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class FBetaLoss(nn.Module):\n",
    "    def __init__(self, beta=4, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        \n",
    "        # Calculate true positives, false positives, and false negatives\n",
    "        tp = torch.sum(y_pred * y_true, dim=[2,3,4])\n",
    "        fp = torch.sum(y_pred * (1 - y_true), dim=[2,3,4])\n",
    "        fn = torch.sum((1 - y_pred) * y_true, dim=[2,3,4])\n",
    "        \n",
    "        # Calculate precision and recall\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "        \n",
    "        # Calculate F-beta score\n",
    "        fb_score = (1 + self.beta**2) * (precision * recall) / \\\n",
    "                   (self.beta**2 * precision + recall + self.epsilon)\n",
    "        \n",
    "        # Apply particle weights\n",
    "        weights = torch.tensor(\n",
    "            [PARTICLE_INFO[p]['weight'] for p in PARTICLE_INFO.keys()]\n",
    "        ).to(y_pred.device)\n",
    "        \n",
    "        weighted_fb = fb_score * weights.view(1, -1)\n",
    "        \n",
    "        return 1 - torch.mean(weighted_fb)"
   ]
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Training implementation with:\n",
    "- Adam optimizer with learning rate scheduling\n",
    "- Model checkpointing for best F-beta score\n",
    "- Training history tracking\n",
    "- Validation phase after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=50):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Initialize loss and optimizer\n",
    "    criterion = FBetaLoss(beta=4)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.ReduceLROnPlateau(optimizer, mode='max', patience=5)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_fbeta': []\n",
    "    }\n",
    "    \n",
    "    best_fbeta = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            inputs = batch['patches'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_fbeta = validate_model(model, val_loader, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_fbeta)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_fbeta > best_fbeta:\n",
    "            best_fbeta = val_fbeta\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_fbeta'].append(val_fbeta)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Val F-beta: {val_fbeta:.4f}')\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Generation\n",
    "\n",
    "Inference pipeline for generating competition submissions:\n",
    "- Sliding window prediction for large tomograms\n",
    "- Peak detection for particle localization\n",
    "- Coordinate transformation and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_submission(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    submissions = []\n",
    "    id_counter = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            tomogram = batch['tomogram'].to(device)\n",
    "            experiment = batch['experiment']\n",
    "            \n",
    "            # Process tomogram in patches\n",
    "            predictions = sliding_window_predict(model, tomogram)\n",
    "            \n",
    "            # Convert predictions to coordinates\n",
    "            for particle_idx, particle_type in enumerate(PARTICLE_INFO.keys()):\n",
    "                if PARTICLE_INFO[particle_type]['weight'] > 0:  # Skip beta-amylase\n",
    "                    coords = get_particle_coordinates(\n",
    "                        predictions[particle_idx],\n",
    "                        threshold=0.5,\n",
    "                        min_distance=PARTICLE_INFO[particle_type]['radius']\n",
    "                    )\n",
    "                    \n",
    "                    for coord in coords:\n",
    "                        submissions.append({\n",
    "                            'id': id_counter,\n",
    "                            'experiment': experiment[0],\n",
    "                            'particle_type': particle_type,\n",
    "                            'x': coord[0],\n",
    "                            'y': coord[1],\n",
    "                            'z': coord[2]\n",
    "                        })\n",
    "                        id_counter += 1\n",
    "    \n",
    "    return pd.DataFrame(submissions)"
   ]
  }
 ]
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization and Evaluation\n",
    "\n",
    "Tools for:\n",
    "- Visualizing training progress\n",
    "- Model architecture summary\n",
    "- Feature map visualization\n",
    "- Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training loss and validation F-beta score\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax1.plot(history['train_loss'], label='Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training Loss Over Time')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot validation F-beta\n",
    "    ax2.plot(history['val_fbeta'], label='Validation F-beta', color='orange')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('F-beta Score')\n",
    "    ax2.set_title('Validation F-beta Score Over Time')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_feature_maps(model, input_tensor):\n",
    "    \"\"\"Visualize intermediate feature maps\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get feature maps from different layers\n",
    "    with torch.no_grad():\n",
    "        x1 = model.init_conv(input_tensor)\n",
    "        x2 = model.enc1(x1)\n",
    "        x3 = model.enc2(x2)\n",
    "        x4 = model.enc3(x3)\n",
    "        x5 = model.bridge(x4)\n",
    "    \n",
    "    # Plot feature maps\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    feature_maps = [input_tensor, x1, x2, x3, x4, x5]\n",
    "    titles = ['Input', 'Initial Conv', 'Encoder 1', 'Encoder 2', 'Encoder 3', 'Bridge']\n",
    "    \n",
    "    for ax, feat_map, title in zip(axes.flat, feature_maps, titles):\n",
    "        # Show middle slice of first channel\n",
    "        middle_slice = feat_map[0, 0, feat_map.shape[2]//2].cpu().numpy()\n",
    "        ax.imshow(middle_slice, cmap='viridis')\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_model_summary(model):\n",
    "    \"\"\"Print model architecture summary\"\"\"\n",
    "    print('CryoETNet Architecture Summary:')\n",
    "    print('================================')\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f'Total parameters: {total_params:,}')\n",
    "    print(f'Trainable parameters: {trainable_params:,}')\n",
    "    print('\\nLayer Structure:')\n",
    "    \n",
    "    def get_layer_info(layer):\n",
    "        if isinstance(layer, (nn.Conv3d, nn.ConvTranspose3d)):\n",
    "            return f'{layer.__class__.__name__}: {layer.in_channels} → {layer.out_channels}'\n",
    "        return layer.__class__.__name__\n",
    "    \n",
    "    for name, layer in model.named_children():\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            print(f'\\n{name}:')\n",
    "            for l in layer:\n",
    "                print(f'  {get_layer_info(l)}')\n",
    "        else:\n",
    "            print(f'\\n{name}: {get_layer_info(layer)}')"
   ]
  }
 ]
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Prediction\n",
    "\n",
    "Implementation of sliding window approach for large tomogram processing:\n",
    "- Handles memory constraints\n",
    "- Overlapping windows for smooth predictions\n",
    "- Efficient processing of 3D volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def sliding_window_predict(model, tomogram, window_size=64, stride=32):\n",
    "    \"\"\"Process large tomogram using sliding window approach\n",
    "    \n",
    "    Args:\n",
    "        model: CryoETNet model\n",
    "        tomogram: Input 3D volume [1, D, H, W]\n",
    "        window_size: Size of processing window\n",
    "        stride: Step size between windows\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Initialize output volume\n",
    "    _, depth, height, width = tomogram.shape\n",
    "    num_classes = model.final_conv.out_channels\n",
    "    output = torch.zeros((num_classes, depth, height, width), device=device)\n",
    "    count = torch.zeros((depth, height, width), device=device)\n",
    "    \n",
    "    # Pad input if necessary\n",
    "    pad_d = (window_size - depth % window_size) % window_size\n",
    "    pad_h = (window_size - height % window_size) % window_size\n",
    "    pad_w = (window_size - width % window_size) % window_size\n",
    "    \n",
    "    if pad_d > 0 or pad_h > 0 or pad_w > 0:\n",
    "        tomogram = F.pad(tomogram, (0, pad_w, 0, pad_h, 0, pad_d))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Slide window across volume\n",
    "        for d in range(0, depth, stride):\n",
    "            for h in range(0, height, stride):\n",
    "                for w in range(0, width, stride):\n",
    "                    # Extract window\n",
    "                    d_end = min(d + window_size, depth)\n",
    "                    h_end = min(h + window_size, height)\n",
    "                    w_end = min(w + window_size, width)\n",
    "                    \n",
    "                    window = tomogram[:, d:d_end, h:h_end, w:w_end]\n",
    "                    \n",
    "                    # Pad window if needed\n",
    "                    if window.shape[1:] != (window_size, window_size, window_size):\n",
    "                        window = F.pad(window, (0, window_size - window.shape[3],\n",
    "                                              0, window_size - window.shape[2],\n",
    "                                              0, window_size - window.shape[1]))\n",
    "                    \n",
    "                    # Process window\n",
    "                    pred = model(window)\n",
    "                    \n",
    "                    # Accumulate predictions\n",
    "                    output[:, d:d_end, h:h_end, w:w_end] += pred[0, :, :d_end-d, :h_end-h, :w_end-w]\n",
    "                    count[d:d_end, h:h_end, w:w_end] += 1\n",
    "    \n",
    "    # Average overlapping predictions\n",
    "    output = output / count.unsqueeze(0)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_particle_coordinates(prediction_map, threshold=0.5, min_distance=60):\n",
    "    \"\"\"Convert prediction map to particle coordinates\n",
    "    \n",
    "    Args:\n",
    "        prediction_map: Model predictions [D, H, W]\n",
    "        threshold: Confidence threshold\n",
    "        min_distance: Minimum distance between particles\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import maximum_filter\n",
    "    from scipy.ndimage import generate_binary_structure\n",
    "    \n",
    "    # Convert to numpy\n",
    "    pred_np = prediction_map.cpu().numpy()\n",
    "    \n",
    "    # Apply threshold\n",
    "    binary = pred_np > threshold\n",
    "    \n",
    "    # Find local maxima\n",
    "    struct = generate_binary_structure(3, 1)\n",
    "    local_max = maximum_filter(pred_np, size=min_distance, mode='constant')\n",
    "    peaks = (pred_np == local_max) & binary\n",
    "    \n",
    "    # Get coordinates\n",
    "    coordinates = np.array(np.where(peaks)).T\n",
    "    \n",
    "    # Sort by confidence\n",
    "    confidences = pred_np[peaks]\n",
    "    sorted_idx = np.argsort(-confidences)\n",
    "    coordinates = coordinates[sorted_idx]\n",
    "    \n",
    "    return coordinates"
   ]
  }
 ]
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "3D augmentation techniques specifically designed for CryoET data:\n",
    "- Rotations and flips\n",
    "- Noise injection\n",
    "- Intensity scaling\n",
    "- Elastic deformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class CryoETAugmentation:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "    \n",
    "    def __call__(self, volume, labels=None):\n",
    "        \"\"\"Apply augmentations to volume and labels\"\"\"\n",
    "        if torch.rand(1) < self.p:\n",
    "            # Random 3D rotation\n",
    "            angles = torch.rand(3) * 360\n",
    "            volume = self._rotate_3d(volume, angles)\n",
    "            if labels is not None:\n",
    "                labels = self._rotate_3d(labels, angles)\n",
    "        \n",
    "        if torch.rand(1) < self.p:\n",
    "            # Add Gaussian noise\n",
    "            noise = torch.randn_like(volume) * 0.1\n",
    "            volume = volume + noise\n",
    "        \n",
    "        if torch.rand(1) < self.p:\n",
    "            # Intensity scaling\n",
    "            scale = torch.rand(1) * 0.4 + 0.8  # 0.8 to 1.2\n",
    "            volume = volume * scale\n",
    "        \n",
    "        if torch.rand(1) < self.p:\n",
    "            # Random flips\n",
    "            dims = torch.randint(0, 3, (2,))\n",
    "            volume = torch.flip(volume, dims=dims)\n",
    "            if labels is not None:\n",
    "                labels = torch.flip(labels, dims=dims)\n",
    "        \n",
    "        return volume, labels\n",
    "    \n",
    "    def _rotate_3d(self, volume, angles):\n",
    "        \"\"\"Apply 3D rotation using affine grid\"\"\"\n",
    "        device = volume.device\n",
    "        theta = torch.tensor([self._get_rotation_matrix_3d(angles)], device=device)\n",
    "        grid = F.affine_grid(theta, volume.unsqueeze(0).size(), align_corners=True)\n",
    "        return F.grid_sample(volume.unsqueeze(0), grid, align_corners=True).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class CryoETMetrics:\n",
    "    def __init__(self, particle_info=PARTICLE_INFO):\n",
    "        self.particle_info = particle_info\n",
    "        \n    def calculate_metrics(self, predictions, targets, radius_factor=0.5):\n",
    "        \"\"\"Calculate precision, recall, and F-beta for each particle type\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        for idx, (particle, info) in enumerate(self.particle_info.items()):\n",
    "            if info['weight'] > 0:  # Skip beta-amylase\n",
    "                pred_coords = get_particle_coordinates(predictions[idx])\n",
    "                true_coords = get_particle_coordinates(targets[idx])\n",
    "                \n",
    "                # Calculate metrics with radius threshold\n",
    "                radius_threshold = info['radius'] * radius_factor\n",
    "                tp, fp, fn = self._calculate_matches(pred_coords, true_coords, radius_threshold)\n",
    "                \n",
    "                precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "                recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "                fbeta = self._calculate_fbeta(precision, recall, beta=4)\n",
    "                \n",
    "                metrics[particle] = {\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f_beta': fbeta,\n",
    "                    'weight': info['weight']\n",
    "                }\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class TrainingConfig:\n",
    "    def __init__(self):\n",
    "        self.model_params = {\n",
    "            'in_channels': 1,\n",
    "            'num_classes': 6,\n",
    "            'initial_filters': 32,\n",
    "            'depth': 4\n",
    "        }\n",
    "        \n",
    "        self.training_params = {\n",
    "            'batch_size': 4,\n",
    "            'epochs': 100,\n",
    "            'learning_rate': 1e-3,\n",
    "            'weight_decay': 1e-4,\n",
    "            'lr_scheduler_patience': 5,\n",
    "            'early_stopping_patience': 10\n",
    "        }\n",
    "        \n",
    "        self.augmentation_params = {\n",
    "            'rotation_prob': 0.5,\n",
    "            'noise_prob': 0.3,\n",
    "            'flip_prob': 0.5,\n",
    "            'intensity_prob': 0.3\n",
    "        }\n",
    "        \n",
    "        self.inference_params = {\n",
    "            'window_size': 64,\n",
    "            'stride': 32,\n",
    "            'confidence_threshold': 0.5,\n",
    "            'nms_threshold': 0.3\n",
    "        }\n",
    "\n",
    "def train_with_config(config):\n",
    "    \"\"\"Initialize and train model with configuration\"\"\"\n",
    "    model = CryoETNet(**config.model_params)\n",
    "    augmenter = CryoETAugmentation(**config.augmentation_params)\n",
    "    metrics = CryoETMetrics()\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config.training_params['learning_rate'],\n",
    "        weight_decay=config.training_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='max',\n",
    "        patience=config.training_params['lr_scheduler_patience']\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    return train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        augmenter=augmenter,\n",
    "        metrics=metrics,\n",
    "        **config.training_params\n",
    "    )"
   ]
  }
 ]
}


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_augmentations(volume, num_augmentations=3):\n",
    "    \"\"\"Visualize different augmentations of a 3D volume\"\"\"\n",
    "    augmenter = CryoETAugmentation(p=1.0)  # Always apply augmentations for visualization\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 5*num_augmentations))\n",
    "    gs = GridSpec(num_augmentations+1, 3)\n",
    "    \n",
    "    # Show original volume\n",
    "    _plot_3d_volume(volume, fig, gs[0], title='Original')\n",
    "    \n",
    "    # Show augmented versions\n",
    "    for i in range(num_augmentations):\n",
    "        aug_volume, _ = augmenter(volume.clone())\n",
    "        _plot_3d_volume(aug_volume, fig, gs[i+1], title=f'Augmentation {i+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _plot_3d_volume(volume, fig, gs, title):\n",
    "    \"\"\"Plot three orthogonal slices of a 3D volume\"\"\"\n",
    "    d, h, w = volume.shape[-3:]\n",
    "    \n",
    "    # XY plane (axial)\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax1.imshow(volume[d//2].cpu(), cmap='gray')\n",
    "    ax1.set_title(f'{title} - Axial')\n",
    "    \n",
    "    # XZ plane (coronal)\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    ax2.imshow(volume[:, h//2].cpu(), cmap='gray')\n",
    "    ax2.set_title(f'{title} - Coronal')\n",
    "    \n",
    "    # YZ plane (sagittal)\n",
    "    ax3 = fig.add_subplot(gs[2])\n",
    "    ax3.imshow(volume[:, :, w//2].cpu(), cmap='gray')\n",
    "    ax3.set_title(f'{title} - Sagittal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "def tune_hyperparameters(num_samples=10):\n",
    "    \"\"\"Tune hyperparameters using Ray Tune with ASHA scheduler\"\"\"\n",
    "    config = {\n",
    "        # Model architecture\n",
    "        'initial_filters': tune.choice([16, 32, 64]),\n",
    "        'depth': tune.choice([3, 4, 5]),\n",
    "        \n",
    "        # Training\n",
    "        'learning_rate': tune.loguniform(1e-4, 1e-2),\n",
    "        'batch_size': tune.choice([2, 4, 8]),\n",
    "        'weight_decay': tune.loguniform(1e-5, 1e-3),\n",
    "        \n",
    "        # Augmentation\n",
    "        'aug_probability': tune.uniform(0.3, 0.7)\n",
    "    }\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=100,  # Maximum epochs\n",
    "        grace_period=10,  # Minimum epochs before pruning\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    \n",
    "    result = tune.run(\n",
    "        train_model_tune,\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        resources_per_trial={'cpu': 4, 'gpu': 1}\n",
    "    )\n",
    "    \n",
    "    best_trial = result.get_best_trial('val_fbeta', mode='max')\n",
    "    print(f'Best trial config: {best_trial.config}')\n",
    "    print(f'Best trial final validation F-beta: {best_trial.last_result[\"val_fbeta\"]}')\n",
    "    \n",
    "    return best_trial.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class CryoETEnsemble:\n",
    "    def __init__(self, model_configs, checkpoint_paths):\n",
    "        \"\"\"Initialize ensemble of CryoETNet models\n",
    "        \n",
    "        Args:\n",
    "            model_configs: List of different model configurations\n",
    "            checkpoint_paths: List of paths to model checkpoints\n",
    "        \"\"\"\n",
    "        self.models = []\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        for config, checkpoint in zip(model_configs, checkpoint_paths):\n",
    "            model = CryoETNet(**config).to(self.device)\n",
    "            model.load_state_dict(torch.load(checkpoint))\n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "    \n",
    "    def predict(self, volume, method='weighted'):\n",
    "        \"\"\"Generate ensemble prediction\n",
    "        \n",
    "        Args:\n",
    "            volume: Input 3D volume\n",
    "            method: Ensemble method ('average', 'weighted', or 'max')\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        weights = [1.0] * len(self.models)  # Can be modified based on validation performance\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for model, weight in zip(self.models, weights):\n",
    "                pred = model(volume.to(self.device))\n",
    "                if method == 'weighted':\n",
    "                    pred = pred * weight\n",
    "                predictions.append(pred)\n",
    "        \n",
    "        if method == 'max':\n",
    "            return torch.max(torch.stack(predictions), dim=0)[0]\n",
    "        else:  # 'average' or 'weighted'\n",
    "            return torch.mean(torch.stack(predictions), dim=0)\n",
    "    \n",
    "    def predict_with_uncertainty(self, volume):\n",
    "        \"\"\"Generate prediction with uncertainty estimation\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                pred = model(volume.to(self.device))\n",
    "                predictions.append(pred)\n",
    "        \n",
    "        predictions = torch.stack(predictions)\n",
    "        mean_pred = torch.mean(predictions, dim=0)\n",
    "        std_pred = torch.std(predictions, dim=0)\n",
    "        \n",
    "        return mean_pred, std_pred"
   ]
  }
 ]
}


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Ensemble Methods\n",
    "\n",
    "Implementing:\n",
    "1. Bagging (Bootstrap Aggregation)\n",
    "2. Stacking with meta-learner\n",
    "3. Snapshot Ensemble\n",
    "4. Monte Carlo Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class AdvancedCryoETEnsemble:\n",
    "    def __init__(self, base_config):\n",
    "        self.base_config = base_config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.models = []\n",
    "        self.meta_learner = None\n",
    "    \n",
    "    def create_bagging_ensemble(self, num_models=5):\n",
    "        \"\"\"Create ensemble using bootstrap sampling\"\"\"\n",
    "        self.models = []\n",
    "        for i in range(num_models):\n",
    "            model = CryoETNet(**self.base_config).to(self.device)\n",
    "            self.models.append({\n",
    "                'model': model,\n",
    "                'type': 'bagging',\n",
    "                'weight': 1.0\n",
    "            })\n",
    "    \n",
    "    def create_snapshot_ensemble(self, model, num_snapshots=5):\n",
    "        \"\"\"Create ensemble from model snapshots during training\"\"\"\n",
    "        self.models = []\n",
    "        for i in range(num_snapshots):\n",
    "            snapshot = copy.deepcopy(model)\n",
    "            self.models.append({\n",
    "                'model': snapshot,\n",
    "                'type': 'snapshot',\n",
    "                'weight': 1.0\n",
    "            })\n",
    "    \n",
    "    def train_stacking_ensemble(self, val_loader):\n",
    "        \"\"\"Train meta-learner for stacking ensemble\"\"\"\n",
    "        # Collect base model predictions\n",
    "        base_predictions = []\n",
    "        true_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = batch['patches'].to(self.device)\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                model_preds = []\n",
    "                for model_dict in self.models:\n",
    "                    pred = model_dict['model'](inputs)\n",
    "                    model_preds.append(pred.cpu())\n",
    "                \n",
    "                base_predictions.append(torch.stack(model_preds))\n",
    "                true_labels.append(labels)\n",
    "        \n",
    "        # Train meta-learner\n",
    "        meta_features = torch.cat(base_predictions, dim=1)\n",
    "        meta_labels = torch.cat(true_labels, dim=0)\n",
    "        \n",
    "        self.meta_learner = nn.Sequential(\n",
    "            nn.Linear(len(self.models) * 6, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 6)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Train meta-learner here...\n",
    "    \n",
    "    def predict_with_mc_dropout(self, volume, num_samples=30):\n",
    "        \"\"\"Monte Carlo Dropout prediction with uncertainty\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        # Enable dropout at test time\n",
    "        for model_dict in self.models:\n",
    "            model = model_dict['model']\n",
    "            model.train()  # Enable dropout\n",
    "            \n",
    "            # Multiple forward passes\n",
    "            model_predictions = []\n",
    "            for _ in range(num_samples):\n",
    "                with torch.no_grad():\n",
    "                    pred = model(volume.to(self.device))\n",
    "                    model_predictions.append(pred)\n",
    "            \n",
    "            predictions.append(torch.stack(model_predictions))\n",
    "            model.eval()\n",
    "        \n",
    "        # Calculate mean and uncertainty\n",
    "        all_predictions = torch.stack(predictions)\n",
    "        mean_pred = torch.mean(all_predictions, dim=(0,1))\n",
    "        epistemic_uncertainty = torch.var(torch.mean(all_predictions, dim=1), dim=0)\n",
    "        aleatoric_uncertainty = torch.mean(torch.var(all_predictions, dim=1), dim=0)\n",
    "        \n",
    "        return {\n",
    "            'prediction': mean_pred,\n",
    "            'epistemic_uncertainty': epistemic_uncertainty,\n",
    "            'aleatoric_uncertainty': aleatoric_uncertainty\n",
    "        }\n",
    "\n",
    "    def visualize_ensemble_predictions(self, volume, true_labels=None):\n",
    "        \"\"\"Visualize predictions from different ensemble members\"\"\"\n",
    "        predictions = []\n",
    "        uncertainties = []\n",
    "        \n",
    "        # Get predictions from each model\n",
    "        for model_dict in self.models:\n",
    "            pred = self.predict_with_mc_dropout(volume, num_samples=10)\n",
    "            predictions.append(pred['prediction'])\n",
    "            uncertainties.append(pred['epistemic_uncertainty'])\n",
    "        \n",
    "        # Plot predictions and uncertainties\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        gs = GridSpec(2, len(self.models) + 1)\n",
    "        \n",
    "        # Plot original volume\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "        ax.imshow(volume[0, volume.shape[1]//2].cpu(), cmap='gray')\n",
    "        ax.set_title('Original')\n",
    "        \n",
    "        if true_labels is not None:\n",
    "            ax = fig.add_subplot(gs[1, 0])\n",
    "            ax.imshow(true_labels[0, true_labels.shape[1]//2].cpu())\n",
    "            ax.set_title('Ground Truth')\n",
    "        \n",
    "        # Plot model predictions and uncertainties\n",
    "        for i, (pred, unc) in enumerate(zip(predictions, uncertainties)):\n",
    "            ax = fig.add_subplot(gs[0, i+1])\n",
    "            ax.imshow(pred[0, pred.shape[1]//2].cpu())\n",
    "            ax.set_title(f'Model {i+1} Prediction')\n",
    "            \n",
    "            ax = fig.add_subplot(gs[1, i+1])\n",
    "            ax.imshow(unc[0, unc.shape[1]//2].cpu(), cmap='hot')\n",
    "            ax.set_title(f'Model {i+1} Uncertainty')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ]
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_ensemble_submission(ensemble, test_loader, confidence_threshold=0.5, uncertainty_threshold=0.2):\n",
    "    \"\"\"Generate submission with ensemble predictions and uncertainty filtering\"\"\"\n",
    "    submissions = []\n",
    "    id_counter = 0\n",
    "    \n",
    "    for batch in test_loader:\n",
    "        tomogram = batch['tomogram']\n",
    "        experiment = batch['experiment']\n",
    "        \n",
    "        # Get ensemble prediction with uncertainty\n",
    "        result = ensemble.predict_with_mc_dropout(tomogram)\n",
    "        predictions = result['prediction']\n",
    "        uncertainties = result['epistemic_uncertainty'] + result['aleatoric_uncertainty']\n",
    "        \n",
    "        # Process each particle type\n",
    "        for particle_idx, particle_type in enumerate(PARTICLE_INFO.keys()):\n",
    "            if PARTICLE_INFO[particle_type]['weight'] > 0:\n",
    "                # Get coordinates where prediction is confident and uncertainty is low\n",
    "                pred_map = predictions[particle_idx] > confidence_threshold\n",
    "                uncertainty_map = uncertainties[particle_idx] < uncertainty_threshold\n",
    "                valid_map = pred_map & uncertainty_map\n",
    "                \n",
    "                coords = get_particle_coordinates(\n",
    "                    valid_map,\n",
    "                    min_distance=PARTICLE_INFO[particle_type]['radius']\n",
    "                )\n",
    "                \n",
    "                # Add to submissions\n",
    "                for coord in coords:\n",
    "                    submissions.append({\n",
    "                        'id': id_counter,\n",
    "                        'experiment': experiment[0],\n",
    "                        'particle_type': particle_type,\n",
    "                        'x': coord[0],\n",
    "                        'y': coord[1],\n",
    "                        'z': coord[2],\n",
    "                        'confidence': float(predictions[particle_idx][coord]),\n",
    "                        'uncertainty': float(uncertainties[particle_idx][coord])\n",
    "                    })\n",
    "                    id_counter += 1\n",
    "    \n",
    "    return pd.DataFrame(submissions)\n",
    "\n",
    "def optimize_submission_thresholds(ensemble, val_loader):\n",
    "    \"\"\"Find optimal confidence and uncertainty thresholds\"\"\"\n",
    "    confidence_range = np.arange(0.3, 0.9, 0.1)\n",
    "    uncertainty_range = np.arange(0.1, 0.5, 0.1)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_thresholds = None\n",
    "    \n",
    "    for conf in confidence_range:\n",
    "        for unc in uncertainty_range:\n",
    "            # Generate validation predictions\n",
    "            predictions = generate_ensemble_submission(\n",
    "                ensemble, val_loader,\n",
    "                confidence_threshold=conf,\n",
    "                uncertainty_threshold=unc\n",
    "            )\n",
    "            \n",
    "            # Calculate F-beta score\n",
    "            score = calculate_fbeta_score(predictions, val_loader.dataset.annotations)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_thresholds = (conf, unc)\n",
    "    \n",
    "    return best_thresholds"
   ]
  }
 ]
}


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced CryoETNet Architecture\n",
    "\n",
    "Added features:\n",
    "- Dropout layers for regularization\n",
    "- Attention mechanism\n",
    "- Modified final layers for better recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class CryoETNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=6, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Encoder path\n",
    "        self.enc1 = self._make_encoder_block(32, 64)\n",
    "        self.enc2 = self._make_encoder_block(64, 128)\n",
    "        self.enc3 = self._make_encoder_block(128, 256)\n",
    "        \n",
    "        # Attention gates\n",
    "        self.attention1 = AttentionGate(256, 512)\n",
    "        self.attention2 = AttentionGate(128, 256)\n",
    "        self.attention3 = AttentionGate(64, 128)\n",
    "        \n",
    "        # Bridge\n",
    "        self.bridge = nn.Sequential(\n",
    "            nn.Conv3d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Decoder path\n",
    "        self.dec3 = self._make_decoder_block(512, 256)\n",
    "        self.dec2 = self._make_decoder_block(256, 128)\n",
    "        self.dec1 = self._make_decoder_block(128, 64)\n",
    "        \n",
    "        # Final layers optimized for recall\n",
    "        self.final_layers = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=dropout_rate),\n",
    "            nn.Conv3d(64, num_classes, kernel_size=1)\n",
    "        )\n",
    "    \n",
    "    def _make_encoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=self.dropout_rate)\n",
    "        )\n",
    "    \n",
    "    def _make_decoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(p=self.dropout_rate)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.init_conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        \n",
    "        # Bridge\n",
    "        x5 = self.bridge(x4)\n",
    "        \n",
    "        # Decoder with attention and skip connections\n",
    "        x = self.dec3(x5)\n",
    "        x4_att = self.attention1(x4, x5)\n",
    "        x = x + x4_att\n",
    "        \n",
    "        x = self.dec2(x)\n",
    "        x3_att = self.attention2(x3, x)\n",
    "        x = x + x3_att\n",
    "        \n",
    "        x = self.dec1(x)\n",
    "        x2_att = self.attention3(x2, x)\n",
    "        x = x + x2_att\n",
    "        \n",
    "        return self.final_layers(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv3d(F_g, F_l, kernel_size=1),\n",
    "            nn.BatchNorm3d(F_l)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv3d(F_l, F_l, kernel_size=1),\n",
    "            nn.BatchNorm3d(F_l)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv3d(F_l, 1, kernel_size=1),\n",
    "            nn.BatchNorm3d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi"
   ]
  }
 ]
}